# NLP Haber Ã–zetleme Projesi

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)
![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.21+-yellow.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

Transformer tabanlÄ± modeller kullanarak CNN/DailyMail veri seti Ã¼zerinde otomatik haber Ã¶zetleme sistemi.

## ğŸ“‹ Proje Ã–zeti

Bu proje, T5-small modeli kullanarak Ä°ngilizce haber metinlerini otomatik olarak Ã¶zetleyen bir sistem geliÅŸtirmektedir. Hugging Face Transformers kÃ¼tÃ¼phanesi ile CNN/DailyMail veri seti Ã¼zerinde fine-tuning yapÄ±larak ROUGE metrikleri ile deÄŸerlendirilmektedir.

### ğŸ¯ Hedefler

- **Model**: T5-small (alternatif: facebook/bart-base)
- **Veri Seti**: CNN/DailyMail (3.0.0)
- **GÃ¶rev**: Article alanÄ±ndan summary alanÄ±nÄ± tahmin etme
- **DeÄŸerlendirme**: ROUGE-1, ROUGE-2, ROUGE-L metrikleri

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Gereksinimler

- Python 3.8+
- CUDA (GPU kullanÄ±mÄ± iÃ§in, opsiyonel)
- 8GB+ RAM (16GB Ã¶nerilir)
- 5GB disk alanÄ±

### Kurulum

1. **Projeyi klonlayÄ±n veya indirin**
```bash
git clone <repository-url>
cd nlp_ozetleme_projesi
```

2. **Sanal ortam oluÅŸturun**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin**
```bash
pip install -r requirements.txt
```

4. **KlasÃ¶r yapÄ±sÄ±nÄ± oluÅŸturun**
```bash
# Windows
mkdir data data\processed data\raw models models\checkpoints outputs outputs\predictions outputs\evaluation_results logs

# macOS/Linux
mkdir -p data/{processed,raw} models/checkpoints outputs/{predictions,evaluation_results} logs
```

### ğŸ”§ KullanÄ±m

#### 1. Tam Pipeline (Ã–nerilen)
```bash
python main.py --mode full
```

#### 2. AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma

**Veri Ã–n Ä°ÅŸleme:**
```bash
python main.py --mode preprocess
```

**Model EÄŸitimi:**
```bash
python main.py --mode train
```

**DeÄŸerlendirme:**
```bash
python main.py --mode evaluate
```

**Demo:**
```bash
python main.py --mode demo
```

#### 3. Jupyter Notebook
```bash
jupyter notebook ozetleme_projesi.ipynb
```

#### 4. EtkileÅŸimli Ã–zetleme
```bash
python inference.py
```

## ğŸ“Š Model PerformansÄ±

Tipik ROUGE skorlarÄ± (test veri seti Ã¼zerinde):

| Metrik | Precision | Recall | F1-Score |
|--------|-----------|--------|----------|
| ROUGE-1 | 0.45 | 0.42 | 0.43 |
| ROUGE-2 | 0.20 | 0.18 | 0.19 |
| ROUGE-L | 0.35 | 0.33 | 0.34 |

*Not: GerÃ§ek sonuÃ§lar veri boyutu ve eÄŸitim parametrelerine baÄŸlÄ± olarak deÄŸiÅŸebilir.*

## ğŸ“ Proje YapÄ±sÄ±

```
nlp_ozetleme_projesi/
â”œâ”€â”€ ğŸ“„ README.md                    # Bu dosya
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python gereksinimleri
â”œâ”€â”€ ğŸ“„ config.py                    # KonfigÃ¼rasyon ayarlarÄ±
â”œâ”€â”€ ğŸ“„ data_preprocessing.py        # Veri Ã¶n iÅŸleme
â”œâ”€â”€ ğŸ“„ model_training.py           # Model eÄŸitimi
â”œâ”€â”€ ğŸ“„ evaluation.py               # Model deÄŸerlendirme
â”œâ”€â”€ ğŸ“„ inference.py                # Ã‡Ä±karÄ±m ve demo
â”œâ”€â”€ ğŸ“„ main.py                     # Ana koordinatÃ¶r
â”œâ”€â”€ ğŸ““ ozetleme_projesi.ipynb      # Jupyter notebook
â”œâ”€â”€ ğŸ“„ rapor.md                    # Proje raporu
â”‚
â”œâ”€â”€ ğŸ“ data/                       # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ ğŸ“ processed/              # Ä°ÅŸlenmiÅŸ veriler
â”‚   â””â”€â”€ ğŸ“ raw/                    # Ham veriler
â”‚
â”œâ”€â”€ ğŸ“ models/                     # EÄŸitilmiÅŸ modeller
â”‚   â””â”€â”€ ğŸ“ checkpoints/            # Model checkpoint'leri
â”‚
â”œâ”€â”€ ğŸ“ outputs/                    # Ã‡Ä±ktÄ±lar
â”‚   â”œâ”€â”€ ğŸ“ predictions/            # Tahmin sonuÃ§larÄ±
â”‚   â””â”€â”€ ğŸ“ evaluation_results/     # DeÄŸerlendirme sonuÃ§larÄ±
â”‚
â””â”€â”€ ğŸ“ logs/                       # Log dosyalarÄ±
```

## âš™ï¸ KonfigÃ¼rasyon

`config.py` dosyasÄ±nda Ã¶nemli parametreler:

```python
# Model ayarlarÄ±
MODEL_NAME = "t5-small"  # Alternatif: "facebook/bart-base"
MAX_INPUT_LENGTH = 512    # GiriÅŸ metni uzunluÄŸu
MAX_TARGET_LENGTH = 128   # Ã–zet uzunluÄŸu

# EÄŸitim ayarlarÄ±
BATCH_SIZE = 4           # Bellek kullanÄ±mÄ±na gÃ¶re ayarlayÄ±n
NUM_EPOCHS = 3           # HÄ±zlÄ± prototip iÃ§in
LEARNING_RATE = 5e-5

# Veri boyutu (hÄ±zlÄ± test iÃ§in kÃ¼Ã§Ã¼k)
TRAIN_SIZE = 5000
VAL_SIZE = 1000
TEST_SIZE = 1000
```

## ğŸ“ˆ SonuÃ§ DosyalarÄ±

Proje Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ktan sonra oluÅŸan Ã¶nemli dosyalar:

- `models/final_model/` - EÄŸitilmiÅŸ model
- `outputs/evaluation_results/evaluation_results.json` - ROUGE skorlarÄ±
- `outputs/evaluation_results/summary_report.txt` - Ã–zet rapor
- `outputs/training_history.json` - EÄŸitim geÃ§miÅŸi
- `outputs/training_curves.png` - EÄŸitim grafikleri
- `logs/` - TÃ¼m iÅŸlem loglarÄ±

## ğŸ” Ã–rnek KullanÄ±m

### Python Script ile
```python
from inference import SummaryGenerator
from config import Config

# Ã–zet Ã¼reticiyi baÅŸlat
config = Config()
summarizer = SummaryGenerator(config)

# Metin Ã¶zetle
text = "Your long article text here..."
result = summarizer.generate_summary(text)
print(result['summary'])
```

### Komut SatÄ±rÄ±ndan
```bash
# Demo modunda Ã§alÄ±ÅŸtÄ±r
python main.py --mode demo

# Ã–zel metin dosyasÄ± Ã¶zetle
python inference.py
```

## ğŸ› ï¸ Sorun Giderme

### YaygÄ±n Hatalar

**1. CUDA HatasÄ±:**
```bash
# CPU kullanÄ±mÄ±na zorla
export CUDA_VISIBLE_DEVICES=""
python main.py
```

**2. Bellek HatasÄ±:**
```python
# config.py iÃ§inde
BATCH_SIZE = 2  # Daha kÃ¼Ã§Ã¼k batch size
TRAIN_SIZE = 1000  # Daha az veri
```

**3. Model Ä°ndirme HatasÄ±:**
```bash
# Hugging Face cache temizle
rm -rf ~/.cache/huggingface/
```

### Performans Ä°puÃ§larÄ±

- **GPU KullanÄ±mÄ±**: CUDA kurulu ise otomatik GPU kullanÄ±lÄ±r
- **Bellek Optimizasyonu**: Batch size'Ä± dÃ¼ÅŸÃ¼rÃ¼n
- **HÄ±z Optimizasyonu**: FP16 precision kullanÄ±n (GPU'da)
- **Veri Boyutu**: Ä°lk testler iÃ§in kÃ¼Ã§Ã¼k veri seti kullanÄ±n

## ğŸ“š Ek Kaynaklar

### Model Mimarileri
- [T5 Paper](https://arxiv.org/abs/1910.10683) - "Exploring the Limits of Transfer Learning"
- [BART Paper](https://arxiv.org/abs/1910.13461) - "Denoising Sequence-to-Sequence Pre-training"

### Veri Seti
- [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) - Hugging Face Dataset

### DeÄŸerlendirme
- [ROUGE Metrics](https://aclanthology.org/W04-1013/) - "ROUGE: A Package for Automatic Evaluation"

### KÃ¼tÃ¼phaneler
- [ğŸ¤— Transformers](https://huggingface.co/transformers/) - Hugging Face Transformers
- [PyTorch](https://pytorch.org/) - Deep Learning Framework
- [Datasets](https://huggingface.co/docs/datasets/) - Hugging Face Datasets

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in:
- Issue aÃ§Ä±n
- E-posta gÃ¶nderin
- Pull request gÃ¶nderin

## ğŸ™ TeÅŸekkÃ¼rler

- Hugging Face ekibine transformers kÃ¼tÃ¼phanesi iÃ§in
- CNN ve Daily Mail veri seti saÄŸlayÄ±cÄ±larÄ±na
- PyTorch topluluÄŸuna

---

â­ Proje yararlÄ±ysa yÄ±ldÄ±z vermeyi unutmayÄ±n!