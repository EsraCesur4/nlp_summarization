# NLP Haber Ã–zetleme Projesi

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)
![Transformers](https://img.shields.io/badge/%20Transformers-4.21+-yellow.svg)

Transformer tabanlÄ± modeller kullanarak CNN/DailyMail veri seti Ã¼zerinde otomatik haber Ã¶zetleme sistemi.

## Proje Ã–zeti

Bu proje, T5-small modeli kullanarak Ä°ngilizce haber metinlerini otomatik olarak Ã¶zetleyen bir sistem geliÅŸtirmektedir. Hugging Face Transformers kÃ¼tÃ¼phanesi ile CNN/DailyMail veri seti Ã¼zerinde fine-tuning yapÄ±larak ROUGE metrikleri ile deÄŸerlendirilmektedir.

### Hedefler

- **Model**: T5-small (alternatif: facebook/bart-base)
- **Veri Seti**: CNN/DailyMail (3.0.0)
- **GÃ¶rev**: Article alanÄ±ndan summary alanÄ±nÄ± tahmin etme
- **DeÄŸerlendirme**: ROUGE-1, ROUGE-2, ROUGE-L metrikleri

## BaÅŸlangÄ±Ã§

### Gereksinimler

- Python 3.8+
- CUDA (GPU kullanÄ±mÄ± iÃ§in, opsiyonel)
- 8GB+ RAM (16GB Ã¶nerilir)
- 5GB disk alanÄ±

### Kurulum

1. **Projeyi klonlayÄ±n veya indirin**
```bash
git clone <repository-url>
cd nlp_ozetleme_projesi
```

2. **Sanal ortam oluÅŸturun**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin**
```bash
pip install -r requirements.txt
```

4. **KlasÃ¶r yapÄ±sÄ±nÄ± oluÅŸturun**
```bash
# Windows
mkdir data data\processed data\raw models models\checkpoints outputs outputs\predictions outputs\evaluation_results logs

# macOS/Linux
mkdir -p data/{processed,raw} models/checkpoints outputs/{predictions,evaluation_results} logs
```

### KullanÄ±m

#### 1. Tam Pipeline (Ã–nerilen)
```bash
python main.py --mode full
```

#### 2. AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma

**Veri Ã–n Ä°ÅŸleme:**
```bash
python main.py --mode preprocess
```

**Model EÄŸitimi:**
```bash
python main.py --mode train
```

**DeÄŸerlendirme:**
```bash
python main.py --mode evaluate
```

**Demo:**
```bash
python main.py --mode demo
```

#### 3. Jupyter Notebook
```bash
jupyter notebook ozetleme_projesi.ipynb
```

#### 4. EtkileÅŸimli Ã–zetleme
```bash
python inference.py
```

## Model PerformansÄ±

Tipik ROUGE skorlarÄ± (test veri seti Ã¼zerinde):

| Metrik  | F1-Score |
|--------|---------|
| ROUGE-1 |  0.3181 |
| ROUGE-2 |  0.1204 |
| ROUGE-L |  0.2250 |
| ROUGE-Lsum | 0.2250 |

*Not: GerÃ§ek sonuÃ§lar veri boyutu ve eÄŸitim parametrelerine baÄŸlÄ± olarak deÄŸiÅŸebilir.*

## ğŸ“ Proje YapÄ±sÄ±

```
nlp_ozetleme_projesi/
â”œâ”€â”€ ğŸ“„ README.md                    # Bu dosya
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python gereksinimleri
â”œâ”€â”€ ğŸ“„ config.py                    # KonfigÃ¼rasyon ayarlarÄ±
â”œâ”€â”€ ğŸ“„ data_preprocessing.py        # Veri Ã¶n iÅŸleme
â”œâ”€â”€ ğŸ“„ model_training.py           # Model eÄŸitimi
â”œâ”€â”€ ğŸ“„ evaluation.py               # Model deÄŸerlendirme
â”œâ”€â”€ ğŸ“„ inference.py                # Ã‡Ä±karÄ±m ve demo
â”œâ”€â”€ ğŸ“„ main.py                     # Ana koordinatÃ¶r
â”œâ”€â”€ ğŸ““ NLP_Summarization.ipynb     # Jupyter notebook
â”œâ”€â”€ ğŸ“„ rapor.md                    # Proje raporu
â”‚
â”œâ”€â”€ ğŸ“ data/                       # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ ğŸ“ processed/              # Ä°ÅŸlenmiÅŸ veriler
â”‚   â””â”€â”€ ğŸ“ raw/                    # Ham veriler
â”‚
â”œâ”€â”€ ğŸ“ models/                     # EÄŸitilmiÅŸ modeller
â”‚   â””â”€â”€ ğŸ“ checkpoints/            # Model checkpoint'leri
â”‚
â”œâ”€â”€ ğŸ“ outputs/                    # Ã‡Ä±ktÄ±lar
â”‚   â”œâ”€â”€ ğŸ“ predictions/            # Tahmin sonuÃ§larÄ±
â”‚   â””â”€â”€ ğŸ“ evaluation_results/     # DeÄŸerlendirme sonuÃ§larÄ±
â”‚
â””â”€â”€ ğŸ“ logs/                       # Log dosyalarÄ±
```

## KonfigÃ¼rasyon

`config.py` dosyasÄ±nda Ã¶nemli parametreler:

```python
# Model ayarlarÄ±
MODEL_NAME = "t5-small"  # Alternatif: "facebook/bart-base"
MAX_INPUT_LENGTH = 512    # GiriÅŸ metni uzunluÄŸu
MAX_TARGET_LENGTH = 128   # Ã–zet uzunluÄŸu

# EÄŸitim ayarlarÄ±
BATCH_SIZE = 4           # Bellek kullanÄ±mÄ±na gÃ¶re ayarlayÄ±n
NUM_EPOCHS = 3           # HÄ±zlÄ± prototip iÃ§in
LEARNING_RATE = 5e-5

# Veri boyutu (hÄ±zlÄ± test iÃ§in kÃ¼Ã§Ã¼k)
TRAIN_SIZE = 5000
VAL_SIZE = 1000
TEST_SIZE = 1000
```

## SonuÃ§ DosyalarÄ±

Proje Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ktan sonra oluÅŸan Ã¶nemli dosyalar:

- `models/final_model/` - EÄŸitilmiÅŸ model
- `outputs/evaluation_results/evaluation_results.json` - ROUGE skorlarÄ±
- `outputs/evaluation_results/summary_report.txt` - Ã–zet rapor
- `outputs/training_history.json` - EÄŸitim geÃ§miÅŸi
- `outputs/training_curves.png` - EÄŸitim grafikleri
- `logs/` - TÃ¼m iÅŸlem loglarÄ±

## Ã–rnek KullanÄ±m

### Python Script ile
```python
from inference import SummaryGenerator
from config import Config

# Ã–zet Ã¼reticiyi baÅŸlat
config = Config()
summarizer = SummaryGenerator(config)

# Metin Ã¶zetle
text = "Your long article text here..."
result = summarizer.generate_summary(text)
print(result['summary'])
```

### Komut SatÄ±rÄ±ndan
```bash
# Demo modunda Ã§alÄ±ÅŸtÄ±r
python main.py --mode demo

# Ã–zel metin dosyasÄ± Ã¶zetle
python inference.py
```

## Ek Kaynaklar

### Model Mimarileri
- [T5 Paper](https://arxiv.org/abs/1910.10683) - "Exploring the Limits of Transfer Learning"
- [BART Paper](https://arxiv.org/abs/1910.13461) - "Denoising Sequence-to-Sequence Pre-training"

### Veri Seti
- [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) - Hugging Face Dataset

### DeÄŸerlendirme
- [ROUGE Metrics](https://aclanthology.org/W04-1013/) - "ROUGE: A Package for Automatic Evaluation"

### KÃ¼tÃ¼phaneler
- [Transformers](https://huggingface.co/transformers/) - Hugging Face Transformers
- [PyTorch](https://pytorch.org/) - Deep Learning Framework
- [Datasets](https://huggingface.co/docs/datasets/) - Hugging Face Datasets
